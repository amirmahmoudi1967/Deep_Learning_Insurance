{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrustPilot_scraper_ProjetPI2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEYXL3qNnBgh"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import math\n",
        "import requests \n",
        "from time import sleep \n",
        "from bs4 import BeautifulSoup\n",
        "from os import path \n",
        "from IPython.display import clear_output, display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvVhaTEdu8su"
      },
      "source": [
        "**Needed configurations to run the scraper.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUPcj4GMpx5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29e9128-d53e-4eab-fcac-84947ac0e796"
      },
      "source": [
        "# Trustpilot review page\n",
        "url = 'https://fr.trustpilot.com/review/direct-assurance.fr'\n",
        "\n",
        "# Data file to save reviews to\n",
        "save_datafile = 'trustpilot_reviews.csv'\n",
        "\n",
        "# Final list to be the dataframe\n",
        "final_list = [] \n",
        "\n",
        "# Handling for Pagination\n",
        "results_per_page = 20 \n",
        "run_pagination_finder = True\n",
        "total_pages = 1\n",
        "\n",
        "# Throttling to avoid spamming page with requests\n",
        "# With sleepTime seconds between every page request\n",
        "throttle = False\n",
        "sleep_time =1 \n",
        "\n",
        "print(f'Scraper set for {url} \\nSaving results to {save_datafile}'\n",
        "      f'\\nRun Pagination Finder: {run_pagination_finder} \\nThrottling On: {throttle}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scraper set for https://fr.trustpilot.com/review/direct-assurance.fr \n",
            "Saving results to trustpilot_reviews.csv\n",
            "Run Pagination Finder: True \n",
            "Throttling On: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-yA6_XwOgu"
      },
      "source": [
        "**Pagination Finder : Total number of pages to scrap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDRfjd9Mpx24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f13976-56a5-48b1-bf92-fad24951c418"
      },
      "source": [
        "## Count amount of pages to scrape\n",
        "if run_pagination_finder:\n",
        "    # Get page\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "    # Get total number of reviews\n",
        "    rating_count = soup.find('span', class_='headline__review-count')\n",
        "    rating_count = int(rating_count.text.replace(',', ''))\n",
        "\n",
        "    # Total pages to scrape\n",
        "    total_pages = math.ceil(rating_count / results_per_page)\n",
        "\n",
        "    print(f'Found total of {total_pages} pages to scrape')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found total of 34 pages to scrape\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXkg5B0XwWo5"
      },
      "source": [
        "**Running the scraper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEp1TLwypx0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5741899-8d26-4b35-b251-3d2acd8e4175"
      },
      "source": [
        "for page_num in range(1, total_pages + 1):    \n",
        "    page = url + '?page=' + str(page_num)\n",
        "    r = requests.get(page)\n",
        "    soup = BeautifulSoup(r.text, 'lxml')\n",
        "        \n",
        "    for paragraph in soup.find_all('section', class_='review__content'):\n",
        "        # get review title\n",
        "        title_section = paragraph.find('h2', class_='review-content__title')   \n",
        "        \n",
        "        if title_section:\n",
        "            title = title_section.find('a').text.strip()\n",
        "        else:\n",
        "            title = ''\n",
        "        \n",
        "        # get review text\n",
        "        content = paragraph.find('p', class_='review-content__text')\n",
        "        \n",
        "        if content:\n",
        "            content = content.text.strip()\n",
        "            \n",
        "            # get review posted date\n",
        "            datedata = json.loads(paragraph.find('div', class_='review-content-header__dates').text)\n",
        "            date = datedata['publishedDate'].split('T')[0]\n",
        "            \n",
        "            # get review rating\n",
        "            rating_class = paragraph.find('div', class_='star-rating')\n",
        "            rating = rating_class.find('img')['alt'][0]   \n",
        "\n",
        "            final_list.append([title, content, date, rating])\n",
        "    \n",
        "    # print progress\n",
        "    clear_output(wait=True)\n",
        "    print(f'scraped page {page_num} of {total_pages}')\n",
        "    \n",
        "    if(throttle): \n",
        "        time.sleep(sleep_time)\n",
        "\n",
        "# Save to pandas dataframe\n",
        "df = pd.DataFrame(final_list, columns=['Title', 'Content', 'Date', 'Rating'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scraped page 34 of 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4w1H9kvwtuZ"
      },
      "source": [
        "**Printing results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BWu_Cubpxyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "fb48d6c2-bf8f-46e4-cd6f-1786c119aca9"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Entreprise que se voudrait être une assurance</td>\n",
              "      <td>Entreprise que se voudrait être une assurance ...</td>\n",
              "      <td>2020-11-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Direct assurance top</td>\n",
              "      <td>Direct assurance topDirect assurance topDirect...</td>\n",
              "      <td>2020-11-20</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jerome - Pratique mafieuse</td>\n",
              "      <td>@jerome : Exactement la même histoire avec aug...</td>\n",
              "      <td>2020-11-19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Très bon rapport Qualité/Prix!</td>\n",
              "      <td>Très bon rapport Qualité/Prix!Voici le code pr...</td>\n",
              "      <td>2020-11-14</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A fuir</td>\n",
              "      <td>Très mauvaise expérience avec cette assurance ...</td>\n",
              "      <td>2020-11-14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>J'étais assuré tous risques chez direct…</td>\n",
              "      <td>J'étais assuré tous risques chez direct assura...</td>\n",
              "      <td>2020-10-27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>Désinvolte envers ses assurés</td>\n",
              "      <td>Le 26/08/2020 j'ai reçu l'avis d'échéance de m...</td>\n",
              "      <td>2020-10-27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>J'ai attendu plus de deux heures une…</td>\n",
              "      <td>J'ai attendu plus de deux heures une dépanneus...</td>\n",
              "      <td>2020-10-24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>Assurance à fuir absolument.</td>\n",
              "      <td>Assurance à fuir absolument.Ils me reclament 1...</td>\n",
              "      <td>2020-10-23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>Assurance nul escro pour des fautes…</td>\n",
              "      <td>Assurance nul des escro incompetent  pour des ...</td>\n",
              "      <td>2020-10-20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>530 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Title  ... Rating\n",
              "0    Entreprise que se voudrait être une assurance  ...      1\n",
              "1                             Direct assurance top  ...      5\n",
              "2                      @jerome - Pratique mafieuse  ...      1\n",
              "3                   Très bon rapport Qualité/Prix!  ...      5\n",
              "4                                           A fuir  ...      1\n",
              "..                                             ...  ...    ...\n",
              "525       J'étais assuré tous risques chez direct…  ...      1\n",
              "526                  Désinvolte envers ses assurés  ...      1\n",
              "527          J'ai attendu plus de deux heures une…  ...      1\n",
              "528                   Assurance à fuir absolument.  ...      1\n",
              "529           Assurance nul escro pour des fautes…  ...      1\n",
              "\n",
              "[530 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frNzsLJTwycY"
      },
      "source": [
        "**Saving the dataframe to a csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ciTxTpApxvc"
      },
      "source": [
        "df.to_csv(save_datafile, encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8BPoLhvTlAV",
        "outputId": "bd8631b3-9d25-46f7-b687-652ed148067a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}